import { formatTimestamp } from '../utils/helpers';

export type PipelineRecommendation = 'audio' | 'visual' | 'hybrid';

export interface VideoMetadataProfile {
  duration: number;
  width: number;
  height: number;
  hasAudioTrack: boolean;
  averageLoudness: number;
  peakLoudness: number;
  silenceRatio: number;
  recommendedPipeline: PipelineRecommendation;
  sampledWindowSeconds: number;
}

interface AnalyzeMetadataOptions {
  /**
   * Maximum amount of video (in seconds) to analyse for audio loudness. The
   * video is played back at an accelerated speed so the actual wall-clock time
   * is significantly smaller.
   */
  maxAnalysisSeconds?: number;
}

function inferHasAudioTrack(video: HTMLVideoElement): boolean {
  const anyVideo = video as any;
  
  // ğŸ¯ å¤šç§æ–¹æ³•æ£€æµ‹éŸ³é¢‘è½¨é“ï¼Œæé«˜å¯é æ€§
  const detectionMethods: Array<{ name: string; result: boolean | null }> = [];
  
  // æ–¹æ³•1: Firefox çš„ mozHasAudio
  if (typeof anyVideo.mozHasAudio === 'boolean') {
    const result = anyVideo.mozHasAudio;
    detectionMethods.push({ name: 'mozHasAudio', result });
    if (result) {
      console.log('[Audio Detection] âœ… Detected audio track via mozHasAudio');
      return true;
    }
  }

  // æ–¹æ³•2: Chrome/Safari çš„ webkitAudioDecodedByteCount
  if (typeof anyVideo.webkitAudioDecodedByteCount === 'number') {
    const result = anyVideo.webkitAudioDecodedByteCount > 0;
    detectionMethods.push({ name: 'webkitAudioDecodedByteCount', result });
    if (result) {
      console.log('[Audio Detection] âœ… Detected audio track via webkitAudioDecodedByteCount:', anyVideo.webkitAudioDecodedByteCount);
      return true;
    }
  }

  // æ–¹æ³•3: æ ‡å‡†çš„ audioTracks API
  if (anyVideo.audioTracks && typeof anyVideo.audioTracks.length === 'number') {
    const result = anyVideo.audioTracks.length > 0;
    detectionMethods.push({ name: 'audioTracks.length', result });
    if (result) {
      console.log('[Audio Detection] âœ… Detected audio track via audioTracks:', anyVideo.audioTracks.length);
      return true;
    }
  }
  
  // æ–¹æ³•4: æ£€æŸ¥ video å…ƒç´ æ˜¯å¦æœ‰ audio å±æ€§ï¼ˆæŸäº›æµè§ˆå™¨ï¼‰
  if (anyVideo.audio !== undefined) {
    const result = Boolean(anyVideo.audio);
    detectionMethods.push({ name: 'video.audio', result });
    if (result) {
      console.log('[Audio Detection] âœ… Detected audio track via video.audio');
      return true;
    }
  }

  // æ–¹æ³•5: æ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘ä¸Šä¸‹æ–‡ï¼ˆé€šè¿‡å°è¯•åˆ›å»ºï¼‰
  // æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•å¯èƒ½ä¸å‡†ç¡®ï¼Œå› ä¸ºå³ä½¿æ²¡æœ‰éŸ³é¢‘è½¨é“ä¹Ÿå¯èƒ½åˆ›å»ºä¸Šä¸‹æ–‡
  
  // è®°å½•æ‰€æœ‰æ£€æµ‹æ–¹æ³•çš„ç»“æœ
  if (detectionMethods.length > 0) {
    console.log('[Audio Detection] Detection methods results:', detectionMethods);
    // å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½è¿”å› falseï¼Œæ‰è¿”å› false
    const allFalse = detectionMethods.every(m => m.result === false);
    if (allFalse) {
      console.warn('[Audio Detection] âš ï¸ All detection methods returned false. May be false negative.');
      // å¯¹äºé•¿è§†é¢‘ï¼Œå³ä½¿æ£€æµ‹å¤±è´¥ä¹Ÿå‡è®¾æœ‰éŸ³é¢‘ï¼ˆå¯èƒ½æ˜¯æ£€æµ‹æ–¹æ³•ä¸æ”¯æŒï¼‰
      return false; // è¿”å› falseï¼Œä½†ä¸Šå±‚é€»è¾‘ä¼šæ ¹æ®è§†é¢‘é•¿åº¦å¼ºåˆ¶ä½¿ç”¨éŸ³é¢‘ç®¡é“
    }
  } else {
    console.warn('[Audio Detection] âš ï¸ No detection methods available. Assuming audio exists.');
  }

  // ğŸ¯ é»˜è®¤è¿”å› trueï¼šå¦‚æœæ— æ³•æ£€æµ‹ï¼Œå‡è®¾æœ‰éŸ³é¢‘è½¨é“
  // è¿™æ ·å¯ä»¥è®©éŸ³é¢‘åˆ†ææ¥æœ€ç»ˆåˆ¤æ–­ï¼Œè€Œä¸æ˜¯åœ¨è¿™é‡Œå°±å¦å®š
  console.log('[Audio Detection] â„¹ï¸ No reliable detection method found. Defaulting to true (will verify via audio analysis).');
  return true;
}

export async function analyzeVideoMetadata(
  file: File,
  options: AnalyzeMetadataOptions = {},
): Promise<VideoMetadataProfile> {
  const { maxAnalysisSeconds = 18 } = options;

  const video = document.createElement('video');
  video.preload = 'metadata';
  video.muted = true;

  const objectUrl = URL.createObjectURL(file);

  try {
    const metadata = await new Promise<{ duration: number; width: number; height: number }>((resolve, reject) => {
      video.onloadedmetadata = () => {
        resolve({ duration: video.duration || 0, width: video.videoWidth || 0, height: video.videoHeight || 0 });
      };
      video.onerror = () => {
        reject(new Error('Failed to load video metadata.'));
      };
      video.src = objectUrl;
    });

    let averageLoudness = 0;
    let peakLoudness = 0;
    let silenceRatio = 1;
    let sampledWindowSeconds = 0;
    
    // ğŸ¯ æš‚æ—¶ä¸åœ¨è¿™é‡Œæ£€æµ‹hasAudioTrackï¼Œå› ä¸ºéŸ³é¢‘æ•°æ®è¿˜æ²¡åŠ è½½
    // å°†åœ¨éŸ³é¢‘æ•°æ®åŠ è½½åå†æ£€æµ‹
    let hasAudioTrack = false;

    try {
      const AudioContextCls = (window.AudioContext || (window as any).webkitAudioContext) as typeof AudioContext | undefined;
      if (!AudioContextCls) {
        throw new Error('AudioContext is not supported in this environment.');
      }

      // ğŸ¯ å…³é”®ä¿®å¤ï¼šåœ¨åˆ†æéŸ³é¢‘å‰ï¼Œç¡®ä¿è§†é¢‘æ•°æ®å·²åŠ è½½
      // preload='metadata' åªåŠ è½½å…ƒæ•°æ®ï¼Œä¸åŠ è½½éŸ³é¢‘æ•°æ®
      // æˆ‘ä»¬éœ€è¦ç­‰å¾…è¶³å¤Ÿçš„æ•°æ®åŠ è½½æ‰èƒ½è¿›è¡ŒéŸ³é¢‘åˆ†æ
      console.log('[Audio Analysis] ğŸ”„ Waiting for audio data to load... (readyState:', video.readyState, ')');
      
      // å¦‚æœreadyState < HAVE_FUTURE_DATA (3)ï¼Œéœ€è¦ç­‰å¾…æ›´å¤šæ•°æ®
      if (video.readyState < 3) {
        // ä¸´æ—¶æ”¹å˜preloadä»¥åŠ è½½éŸ³é¢‘æ•°æ®
        video.preload = 'auto';
        
        // ç­‰å¾…canplayäº‹ä»¶ï¼ˆreadyState >= HAVE_FUTURE_DATAï¼‰
        await new Promise<void>((resolve, reject) => {
          const timeoutId = setTimeout(() => {
            console.warn('[Audio Analysis] âš ï¸ Timeout waiting for audio data. Proceeding anyway...');
            resolve();
          }, 5000); // 5ç§’è¶…æ—¶
          
          const onCanPlay = () => {
            clearTimeout(timeoutId);
            console.log('[Audio Analysis] âœ… Audio data loaded (readyState:', video.readyState, ')');
            resolve();
          };
          
          const onError = () => {
            clearTimeout(timeoutId);
            console.warn('[Audio Analysis] âš ï¸ Error loading audio data');
            resolve(); // ä¸è¦rejectï¼Œç»§ç»­å°è¯•åˆ†æ
          };
          
          video.addEventListener('canplay', onCanPlay, { once: true });
          video.addEventListener('error', onError, { once: true });
          
          // å¦‚æœå·²ç»å¯ä»¥æ’­æ”¾äº†ï¼Œç«‹å³resolve
          if (video.readyState >= 3) {
            clearTimeout(timeoutId);
            video.removeEventListener('canplay', onCanPlay);
            video.removeEventListener('error', onError);
            console.log('[Audio Analysis] âœ… Audio data already loaded (readyState:', video.readyState, ')');
            resolve();
          } else {
            // è§¦å‘åŠ è½½
            video.load();
          }
        });
      } else {
        console.log('[Audio Analysis] âœ… Audio data already available (readyState:', video.readyState, ')');
      }

      // ğŸ¯ ç°åœ¨éŸ³é¢‘æ•°æ®å·²åŠ è½½ï¼Œå¯ä»¥è¿›è¡Œå‡†ç¡®çš„éŸ³é¢‘è½¨é“æ£€æµ‹äº†
      hasAudioTrack = inferHasAudioTrack(video);
      console.log('[Audio Analysis] Audio track detection after data loaded:', hasAudioTrack);

      const audioContext = new AudioContextCls();
      const source = audioContext.createMediaElementSource(video);
      const analyser = audioContext.createAnalyser();
      const gain = audioContext.createGain();

      analyser.fftSize = 2048;
      gain.gain.value = 0; // Avoid audible playback while still allowing analysis

      source.connect(analyser);
      analyser.connect(gain);
      gain.connect(audioContext.destination);

      const dataArray = new Uint8Array(analyser.fftSize);
      const amplitudeSamples: number[] = [];

      // ğŸ¯ æ ¹æ®è§†é¢‘é•¿åº¦åŠ¨æ€è°ƒæ•´é‡‡æ ·æ—¶é•¿å’Œä½ç½®
      // å¯¹äºé•¿è§†é¢‘ï¼Œä»å¤šä¸ªä½ç½®é‡‡æ ·ä»¥è·å¾—æ›´å‡†ç¡®çš„ç»“æœ
      const duration = metadata.duration || 0;
      let analysisSeconds = maxAnalysisSeconds;
      
      // å¯¹äºé•¿è§†é¢‘ï¼ˆ>10åˆ†é’Ÿï¼‰ï¼Œå¢åŠ é‡‡æ ·æ—¶é•¿
      if (duration > 600) {
        analysisSeconds = Math.min(30, duration * 0.05); // æœ€å¤š30ç§’æˆ–è§†é¢‘çš„5%
      } else if (duration > 300) {
        analysisSeconds = Math.min(24, duration * 0.08); // æœ€å¤š24ç§’æˆ–è§†é¢‘çš„8%
      }
      
      const effectiveAnalysisSeconds = Math.min(duration || analysisSeconds, analysisSeconds);
      sampledWindowSeconds = effectiveAnalysisSeconds;

      if (effectiveAnalysisSeconds > 0) {
        const playbackRate = duration > 600 ? 4 : duration > 300 ? 3 : 2;
        
        // ğŸ¯ æ”¹è¿›é‡‡æ ·ä½ç½®ç­–ç•¥ï¼šä»è§†é¢‘ä¸­é—´å’Œå¤šä¸ªä½ç½®é‡‡æ ·ï¼Œè€Œä¸æ˜¯æœ«å°¾
        // å¯¹äºè®¿è°ˆç±»è§†é¢‘ï¼Œä¸­é—´éƒ¨åˆ†æ›´å¯èƒ½æœ‰å¯¹è¯å†…å®¹
        const samplePositions: number[] = [];
        
        if (duration > 600) {
          // é•¿è§†é¢‘ï¼šä»25%ã€50%ã€75%ä½ç½®é‡‡æ ·
          samplePositions.push(duration * 0.25, duration * 0.50, duration * 0.75);
        } else if (duration > 300) {
          // ä¸­ç­‰è§†é¢‘ï¼šä»30%ã€60%ä½ç½®é‡‡æ ·
          samplePositions.push(duration * 0.30, duration * 0.60);
        } else {
          // çŸ­è§†é¢‘ï¼šä»ä¸­é—´é‡‡æ ·
          samplePositions.push(duration * 0.50);
        }

        // åˆå¹¶æ‰€æœ‰é‡‡æ ·ç‚¹çš„æ•°æ®
        for (const samplePosition of samplePositions) {
          const segmentDuration = effectiveAnalysisSeconds / samplePositions.length;
          const segmentStartTime = Math.max(0, Math.min(duration - segmentDuration, samplePosition - segmentDuration / 2));
          
          video.currentTime = segmentStartTime;
          video.playbackRate = playbackRate;

          await audioContext.resume().catch(() => {});
          
          // ğŸ¯ å…³é”®ä¿®å¤ï¼šç­‰å¾…è§†é¢‘seekå®Œæˆå¹¶çœŸæ­£å¼€å§‹æ’­æ”¾
          // ä¸è¦ä½¿ç”¨å›ºå®šè¶…æ—¶ï¼Œè€Œæ˜¯ç­‰å¾…'seeked'å’Œ'playing'äº‹ä»¶
          await new Promise<void>((resolve) => {
            let seeked = false;
            let playing = false;
            const timeoutId = setTimeout(() => {
              console.warn('[Audio Analysis] âš ï¸ Timeout waiting for video to start playing at position', segmentStartTime);
              resolve();
            }, 3000);
            
            const checkReady = () => {
              if (seeked && playing) {
                clearTimeout(timeoutId);
                // å†ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©éŸ³é¢‘ç¼“å†²åŒºå¡«å……
                setTimeout(resolve, 300);
              }
            };
            
            const onSeeked = () => {
              seeked = true;
              console.log('[Audio Analysis] âœ… Seeked to position', video.currentTime);
              checkReady();
            };
            
            const onPlaying = () => {
              playing = true;
              console.log('[Audio Analysis] âœ… Video playing at position', video.currentTime);
              checkReady();
            };
            
            video.addEventListener('seeked', onSeeked, { once: true });
            video.addEventListener('playing', onPlaying, { once: true });
            
            // å¼€å§‹æ’­æ”¾
            video.play().catch((err) => {
              console.warn('[Audio Analysis] âš ï¸ Play failed:', err);
              clearTimeout(timeoutId);
              resolve(); // å³ä½¿å¤±è´¥ä¹Ÿç»§ç»­
            });
          });

          const wallClockLimit = (segmentDuration / playbackRate) * 1000;
          const startTime = performance.now();

          while (performance.now() - startTime < wallClockLimit && !video.ended && video.currentTime < duration) {
            analyser.getByteTimeDomainData(dataArray);

            let sum = 0;
            let max = 0;
            for (let i = 0; i < dataArray.length; i++) {
              const normalized = (dataArray[i] - 128) / 128;
              const amplitude = Math.abs(normalized);
              sum += amplitude;
              if (amplitude > max) {
                max = amplitude;
              }
            }

            const averageAmplitude = sum / dataArray.length;
            amplitudeSamples.push(averageAmplitude);
            if (max > peakLoudness) {
              peakLoudness = max;
            }

            await new Promise((resolve) => setTimeout(resolve, 120));
          }

          video.pause();
          
          // åœ¨é‡‡æ ·ä¸‹ä¸€ä¸ªä½ç½®å‰ç¨ä½œç­‰å¾…
          if (samplePositions.indexOf(samplePosition) < samplePositions.length - 1) {
            await new Promise((resolve) => setTimeout(resolve, 100));
          }
        }

        averageLoudness = amplitudeSamples.length
          ? amplitudeSamples.reduce((acc, value) => acc + value, 0) / amplitudeSamples.length
          : 0;

        // ğŸ¯ æ”¹è¿›é™éŸ³é˜ˆå€¼ï¼šä½¿ç”¨æ›´æ™ºèƒ½çš„é˜ˆå€¼æ£€æµ‹
        // åŸºäºå®é™…éŸ³é¢‘æ•°æ®çš„åˆ†å¸ƒï¼Œè€Œä¸æ˜¯å›ºå®šé˜ˆå€¼
        const sortedAmplitudes = [...amplitudeSamples].sort((a, b) => a - b);
        const medianAmplitude = sortedAmplitudes[Math.floor(sortedAmplitudes.length / 2)];
        const q1Amplitude = sortedAmplitudes[Math.floor(sortedAmplitudes.length * 0.25)];
        
        // åŠ¨æ€é˜ˆå€¼ï¼šä½¿ç”¨ä¸­ä½æ•°çš„30%æˆ–Q1ï¼Œå–è¾ƒå¤§å€¼ï¼Œä½†æœ€ä½ä¸ä½äº0.01
        const silentThreshold = Math.max(0.01, Math.max(medianAmplitude * 0.3, q1Amplitude * 0.5));
        
        const silentCount = amplitudeSamples.filter((sample) => sample < silentThreshold).length;
        silenceRatio = amplitudeSamples.length ? silentCount / amplitudeSamples.length : 1;

        // ğŸ¯ æ”¹è¿›hasAudioTrackåˆ¤æ–­ï¼šä½¿ç”¨peakLoudnessè€Œä¸æ˜¯æ‰€æœ‰æ ·æœ¬
        // åªè¦å³°å€¼è¶…è¿‡é˜ˆå€¼ï¼Œå°±è®¤ä¸ºæœ‰éŸ³é¢‘è½¨é“
        if (amplitudeSamples.length > 0) {
          // å¦‚æœpeakLoudness > 0.02ï¼Œè‚¯å®šæœ‰éŸ³é¢‘
          // æˆ–è€…å¦‚æœaverageLoudness > 0.005ï¼Œä¹Ÿè®¤ä¸ºæœ‰éŸ³é¢‘
          // å¯¹äºé•¿è§†é¢‘ï¼Œé™ä½é˜ˆå€¼ä»¥é¿å…è¯¯åˆ¤
          const duration = metadata.duration || 0;
          const peakThreshold = duration > 1800 ? 0.015 : 0.02; // é•¿è§†é¢‘é™ä½é˜ˆå€¼
          const avgThreshold = duration > 1800 ? 0.003 : 0.005; // é•¿è§†é¢‘é™ä½é˜ˆå€¼
          
          const hasSignificantAudio = peakLoudness > peakThreshold || averageLoudness > avgThreshold;
          
          // ğŸ¯ é‡è¦ï¼šå¦‚æœåˆå§‹æ£€æµ‹åˆ°æœ‰éŸ³é¢‘è½¨é“ï¼ˆinferHasAudioTrackï¼‰ï¼Œå³ä½¿é‡‡æ ·æ•°æ®ä¸ç†æƒ³ä¹Ÿä¿æŒä¸ºtrue
          // å› ä¸ºå¯èƒ½æ˜¯é‡‡æ ·ä½ç½®æ°å¥½æ˜¯é™éŸ³éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯çœŸçš„æ²¡æœ‰éŸ³é¢‘
          if (hasAudioTrack) {
            // åˆå§‹æ£€æµ‹æœ‰éŸ³é¢‘ï¼Œå³ä½¿é‡‡æ ·æ•°æ®ä¸ç†æƒ³ä¹Ÿä¿æŒä¸ºtrueï¼ˆå¯èƒ½æ˜¯é‡‡æ ·ä½ç½®é—®é¢˜ï¼‰
            if (!hasSignificantAudio) {
              console.warn('[Audio Analysis] âš ï¸ Initial detection found audio track, but samples show low amplitude. May be sampling issue. Keeping hasAudioTrack=true.');
            }
            // ä¿æŒ hasAudioTrack = true
          } else {
            // åˆå§‹æ£€æµ‹æ²¡æœ‰éŸ³é¢‘ï¼Œä½†é‡‡æ ·æ•°æ®æœ‰ä¿¡å·ï¼Œæ›´æ–°ä¸ºtrue
            hasAudioTrack = hasSignificantAudio;
          }
          
          console.log('[Audio Analysis]', {
            samples: amplitudeSamples.length,
            averageLoudness: averageLoudness.toFixed(4),
            peakLoudness: peakLoudness.toFixed(4),
            silentThreshold: silentThreshold.toFixed(4),
            silenceRatio: (silenceRatio * 100).toFixed(1) + '%',
            hasAudioTrack,
            samplePositions: samplePositions.length,
            hasSignificantAudio,
            peakThreshold: peakThreshold.toFixed(4),
            avgThreshold: avgThreshold.toFixed(4)
          });
        } else {
          // æ²¡æœ‰é‡‡æ ·æ•°æ®ï¼Œä¿æŒåˆå§‹æ£€æµ‹ç»“æœ
          console.warn('[Audio Analysis] âš ï¸ No samples collected. Keeping initial hasAudioTrack value:', hasAudioTrack);
        }

        video.pause();
      }

      await audioContext.close();
    } catch (error) {
      console.warn('[Audio Analysis] Audio analysis failed:', error);
      // ğŸ¯ æ”¹è¿›ï¼šå¦‚æœéŸ³é¢‘åˆ†æå¤±è´¥ï¼Œä¸è¦ç›´æ¥å‡è®¾æ²¡æœ‰éŸ³é¢‘è½¨é“
      // å¯¹äºé•¿è§†é¢‘ï¼Œå¯èƒ½æ˜¯åˆ†æè¶…æ—¶æˆ–å…¶ä»–æŠ€æœ¯é—®é¢˜ï¼Œè€Œä¸æ˜¯çœŸçš„æ²¡æœ‰éŸ³é¢‘
      // ä¿æŒ hasAudioTrack çš„åˆå§‹å€¼ï¼ˆä» inferHasAudioTrack è·å–ï¼‰ï¼Œä¸è¦å¼ºåˆ¶è®¾ä¸º false
      // è¿™æ ·å¯ä»¥è®©ä¸Šå±‚é€»è¾‘æ ¹æ®è§†é¢‘é•¿åº¦å†³å®šæ˜¯å¦å¼ºåˆ¶ä½¿ç”¨éŸ³é¢‘ç®¡é“
      if (amplitudeSamples.length === 0) {
        // åªæœ‰åœ¨å®Œå…¨æ²¡æœ‰é‡‡æ ·æ•°æ®æ—¶æ‰é‡ç½®
        console.warn('[Audio Analysis] No samples collected. Keeping initial hasAudioTrack value:', hasAudioTrack);
        // ä¸å¼ºåˆ¶è®¾ç½® hasAudioTrack = falseï¼Œä¿æŒåˆå§‹æ£€æµ‹ç»“æœ
      }
      // å¦‚æœå·²ç»æœ‰é‡‡æ ·æ•°æ®ï¼Œä¿æŒç°æœ‰çš„ averageLoudness å’Œ peakLoudness
      if (amplitudeSamples.length === 0) {
        averageLoudness = 0;
        peakLoudness = 0;
        silenceRatio = 1;
      }
    }

    const recommendedPipeline: PipelineRecommendation = (() => {
      if (!hasAudioTrack || averageLoudness < 0.01 || silenceRatio > 0.75) {
        return 'visual';
      }
      if (averageLoudness < 0.035 || silenceRatio > 0.45) {
        return 'hybrid';
      }
      return 'audio';
    })();

    return {
      duration: metadata.duration,
      width: metadata.width,
      height: metadata.height,
      hasAudioTrack,
      averageLoudness,
      peakLoudness,
      silenceRatio,
      recommendedPipeline,
      sampledWindowSeconds,
    };
  } finally {
    video.pause();
    video.removeAttribute('src');
    video.load();
    URL.revokeObjectURL(objectUrl);
  }
}

export function describeAudioProfile(profile: VideoMetadataProfile): string {
  const loudness = profile.averageLoudness.toFixed(3);
  const silence = `${Math.round(profile.silenceRatio * 100)}%`;
  const durationText = formatTimestamp(profile.duration);

  return `Duration: ${durationText}, Avg Loudness: ${loudness}, Silence Ratio: ${silence}, Pipeline: ${profile.recommendedPipeline}`;
}
