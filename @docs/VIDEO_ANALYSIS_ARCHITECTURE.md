# 无声视频字幕增强与帧级解析架构设计

本设计方案旨在提升 AI Videos Play 在**无音频或配音缺失的视频场景**下的字幕生成质量，并在处理**超长/大尺寸视频**时保持高吞吐、可恢复和可观测。

## 目标
- 自动检测音轨质量，智能切换到帧级语义分析流程。
- 通过多通道融合（音频、OCR、视觉语义）生成稳健字幕。
- 面向长视频，提供分段化、幂等的可恢复处理能力。
- 建立统一的错误上报、断点续跑、审计和回滚机制。

---

## 1. 总体架构
```
+--------------------+        +---------------------+        +--------------------+
|  Upload Service    |        |  Metadata Service   |        |  Job Orchestrator  |
|  (浏览器/CLI)       |  --->  |  (ffprobe/mediainfo)|  --->  |  (BullMQ/Temporal) |
+--------------------+        +---------------------+        +--------------------+
                                                             |  Pipeline Router   |
                                                             +----------+---------+
                                                                        |
        +-----------------------------------音频存在---------------------+-------------------+
        |                                                                                        |
+--------------------+                                                   +--------------------+
|  Audio Pipeline    |                                                   |  Visual Pipeline   |
|  (Whisper/Gemini)  |                                                   |  (CLIP/OCR/LLM)    |
+----------+---------+                                                   +----------+---------+
           |                                                                            |
           v                                                                            v
+--------------------+                                                   +--------------------+
|  Alignment & Merge |  <-----------多模态加权融合------------------------|  Context Builder   |
+----------+---------+                                                   +----------+---------+
           |                                                                            |
           +--------------------> Subtitle Generator <----------------------------------+
                                   (LLM Prompt Orchestrator)
```

### 核心职责
1. **Metadata Service**：解析视频基础信息（时长、分辨率、音轨数量、关键帧间隔），判定是否进入音频或帧级流程。
2. **Job Orchestrator**：统一的工作流控制中心。推荐使用 [Temporal](https://temporal.io/) 或 [BullMQ](https://docs.bullmq.io/) 管理任务队列、重试、超时与幂等性。
3. **Audio Pipeline**：对高质量音轨执行语音识别；包含降噪、音量归一化、转码。
4. **Visual Pipeline**：在音轨缺失或质量不足时启用。
   - **帧采样与摘要**：动态帧率采样、场景检测（ffmpeg `select='gt(scene,0.4)'`）。
   - **视觉语义提取**：CLIP、BLIP2 等模型提取语义标签；OCR 检测屏幕字幕/幻灯片文字。
   - **上下文构建**：将视觉与 OCR 片段形成时间轴事件，供 LLM 生成描述性字幕。
5. **Alignment & Merge**：对来自多模态的时间片进行对齐，解决帧级结果缺乏精确时间戳问题，可使用动态时间规整（DTW）或基于场景切换的分段对齐。
6. **Subtitle Generator**：封装 LLM Prompt，联合上下文和模板输出最终 SRT/VTT。

---

## 2. 帧级分析流程细化

### 2.1 帧采样策略
- **基础速率**：默认每秒 1 帧 (1fps)。
- **动态调整**：
  - 若检测到快速场景切换（`scene > 0.6`），提升至 3fps。
  - 对静态画面超过 10 秒的片段降到 0.3fps，减少冗余。
- **关键帧优先**：使用 `ffprobe` 读取 GOP（Group of Pictures）信息，仅抽取关键帧附近的画面，降低解码开销。

### 2.2 视觉语义
- **图像 Caption**：BLIP2 / LLaVA 生成完整描述。
- **物体识别**：Detectron2 / YOLOv8 识别核心实体，用于构建主题词。
- **OCR**：PaddleOCR / Tesseract 识别屏幕文字，保留位置与置信度，供后续提示词过滤。
- **镜头变化检测**：记录场景边界，结合字幕分段。

### 2.3 时间轴构建
```typescript
interface VisualEvent {
  start: number; // 秒
  end: number;
  caption: string; // 视觉模型生成
  ocrText?: string;
  tags: string[]; // 识别出的关键实体
  confidence: number;
}
```
- 将连续的视觉事件按主题合并，构建**视觉语义时间线**。
- 对 OCR 结果采用置信度阈值（如 0.7）过滤；对低置信度片段标记为 `needs_review`，交由人工审核或提示用户。

---

## 3. 错误分析与中断处理

### 3.1 错误分类
| 类别 | 示例 | 处理策略 |
|------|------|----------|
| 输入错误 | 视频损坏、格式不支持 | 立即失败并提示；记录在 `job_failures` 表 |
| 资源不足 | 解码超时、显存不足 | 自动降级：降低分辨率或调整 batch 大小，记录告警 |
| 模型错误 | 模型服务不可用 | 尝试切换备用模型或使用缓存结果 |
| 流程中断 | Worker 重启、网络波动 | 依赖工作流引擎的 Checkpoint 重试 |

### 3.2 幂等与断点续跑
- 所有任务引入 `jobId + segmentId` 唯一键，结果写入对象存储（S3/GCS）并记录状态表。
- 处理阶段持久化：
  - `metadata_extracted`
  - `audio_processed`
  - `visual_events_ready`
  - `subtitle_generated`
- Worker 重启后按状态恢复，避免重复解码/推理。

### 3.3 观测与调试
- 引入集中化日志（OpenTelemetry），记录关键指标：
  - 每段视频的采样帧数、OCR 召回率、模型耗时。
  - 音频信噪比 (SNR)、静音比率。
- 对失败任务提供 `failure_report.json`，包含上下游服务响应、重试次数和建议处理。

---

## 4. 面向大视频的优化

1. **分片处理**：
   - 将视频按 5~10 分钟切片，切片间保持重叠 2 秒用于平滑衔接。
   - 每个切片独立进入音频/视觉流水线，最终在 Merge 阶段拼接。
2. **层次缓存**：
   - 原始帧与中间结果保存在临时对象存储（如 Redis + S3），命中后直接读取。
3. **推理调度**：
   - 使用队列优先级：短视频优先级高；长视频拆分子任务后统一排队。
4. **GPU 资源复用**：
   - 音频与视觉推理分布在不同 Worker Pool；对于视觉任务，采用批处理推理（一次推理多个帧）。
5. **结果验证**：
   - 对合并后的字幕运行一致性检查（时间不倒退、间隔合理）。
   - 对跨度超过 30 秒且语义弱的片段触发“待审核”标记。

---

## 5. 开发落地建议

| 模块 | 建议技术栈 | 说明 |
|------|------------|------|
| Metadata Service | `ffprobe`, `fluent-ffmpeg` | 已有 Node.js 项目中易集成 |
| Job Orchestrator | `Temporal`, `BullMQ`, `Redis` | 根据现有基础设施选择 |
| Audio Pipeline | Whisper + 自适应速率 (参考 `LONG_VIDEO_OPTIMIZATION.md`) | 自动检测静音/语速 |
| Visual Pipeline | `opencv4nodejs`, `@xenova/transformers`, `paddleocr` | Node 环境推理或调用 Python 微服务 |
| Subtitle Generator | Gemini / GPT-4o | Prompt 中融合视觉事件和 OCR 文本 |
| Monitoring | `OpenTelemetry`, `Prometheus`, `Sentry` | 日志、指标、错误追踪 |

### 与现有代码的集成
- 在 `services` 目录下新增 `videoAnalysis` 服务层，封装音频/视觉流水线调用。
- 在 `workers` 目录中新增 `visualTranscript.worker.ts`，负责消费帧级任务。
- 将 `LONG_VIDEO_OPTIMIZATION.md` 中的策略纳入 `videoAnalysis` 的配置（如 `maxExtractionDuration`、`adaptivePlaybackRate`）。

---

## 6. 测试与验证策略
1. **单元测试**：
   - 元数据解析、静音检测、帧采样策略逻辑。
2. **集成测试**：
   - 构造无音频/有噪音视频样例，验证是否正确回落到视觉流程。
   - 对长视频运行端到端测试，确保分片合并正确。
3. **回归基准**：
   - 维护一组多语言、不同场景的视频样本，每次发布前生成字幕并对比（BLEU、ROUGE、人工评估）。
4. **混沌测试**：
   - 模拟 Worker 崩溃、网络超时，验证工作流的重试与断点续跑。

---

## 7. 后续扩展
- **主题标签生成**：基于视觉/文本结果生成视频章节目录。
- **交互式字幕编辑器**：允许用户在浏览器中快速修订帧级字幕结果。
- **知识库联动**：将 OCR 文本与企业知识库比对，提供术语解释。

---

通过以上架构设计，系统能够在无音频场景下仍然生成高质量字幕，并在处理大体量视频时保持可靠性与可维护性，为未来功能扩展奠定坚实基础。
